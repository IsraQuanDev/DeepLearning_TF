{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 02:32:47.206889: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-07 02:32:49.693205: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 02:32:49.693230: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-07 02:32:53.484108: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 02:32:53.484240: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 02:32:53.484251: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.15.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (23.0)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b'5680e\\r\\nX-Real-IP: 177.228.54.71\\r\\nX-Forwarded-For: 177.2', b'.54.71\\r\\nX-Forwarded-Host: israquandev-improved-sp']\n",
      "Bad pipe message: %s [b'e-telegram-gv767p6j59rh9656-39591.preview.app.github.dev\\r\\nX-Forwarded-Port: 443\\r\\nX-Forwarded-Pro', b': https\\r\\nX-Forwarded-Scheme: https\\r\\nX-Original-URI: /\\r\\nX-Scheme: https\\r\\nConnection: Keep-Alive\\r\\nProxy-Connection: K', b'p-Alive\\r\\ncache-control: max-age=0\\r\\nupgrade-insecure-requests: 1\\r\\nuser-agent: Mozilla/5.0 (Windows NT', b'0.0; Win64; x64) AppleWebKit/53', b'36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36 ']\n",
      "Bad pipe message: %s [b'g/110.0.1587.63\\r\\naccept: text/html,application/xhtml+xml,application']\n",
      "Bad pipe message: %s [b'ml;q=0.9,image/webp,image/apng,*/*;q=0.8,appli']\n",
      "Bad pipe message: %s [b'tion/signed-exchange;v=b3;q=0.7\\r\\nsec-fetch-site: same-site\\r\\nsec-fetch-mode: navigate\\r\\nsec-fetch-de', b': document\\r\\nsec-ch-ua: \"Chromium\";v=\"110\", \"Not A(Brand\";v=\"24\", \"Microsoft Edge\";v=\"110\"\\r\\nsec-ch-ua-mobile: ?0\\r\\ns']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.51.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-15.0.6.1-py2.py3-none-manylinux2010_x86_64.whl (21.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.5/21.5 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (4.5.0)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (1.24.2)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/python/3.10.4/lib/python3.10/site-packages (from tensorflow) (58.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/codespace/.local/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.16.2-py2.py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.28.2)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.2)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, pyasn1, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyasn1-modules, protobuf, opt-einsum, oauthlib, markdown, keras, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "\u001b[33m  WARNING: The scripts pyrsa-decrypt, pyrsa-encrypt, pyrsa-keygen, pyrsa-priv2pub, pyrsa-sign and pyrsa-verify are installed in '/usr/local/python/3.10.4/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script markdown_py is installed in '/usr/local/python/3.10.4/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script google-oauthlib-tool is installed in '/usr/local/python/3.10.4/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script tensorboard is installed in '/usr/local/python/3.10.4/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/usr/local/python/3.10.4/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 flatbuffers-23.3.3 gast-0.4.0 google-auth-2.16.2 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.3 h5py-3.8.0 keras-2.11.0 libclang-15.0.6.1 markdown-3.4.1 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.2.0 werkzeug-2.2.3 wrapt-1.15.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 02:33:26.675299: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-07 02:33:26.687009: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-07 02:33:26.687044: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (codespaces-4c9216): /proc/driver/nvidia/version does not exist\n",
      "2023-03-07 02:33:26.687951: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Build a simple Sequential model\n",
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare model inputs and outputs for training\n",
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0162\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0158\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0155\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0152\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0149\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0146\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0143\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0140\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0137\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0134\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0131\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0129\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0126\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0123\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0121\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0118\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0116\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0114\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0111\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0109\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0107\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0105\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0102\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0100\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0098\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0096\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0094\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0092\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0090\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0089\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0087\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0085\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0083\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0082\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0080\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0078\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0077\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0075\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0073\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0072\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0070\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0069\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0068\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0066\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0065\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0064\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0062\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0061\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0060\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0058\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0057\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0056\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0055\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0054\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0053\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0052\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0051\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0050\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0049\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0048\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0047\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0046\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0045\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0044\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0043\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0042\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0041\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0040\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0039\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0039\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0038\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0037\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0036\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0036\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0035\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0034\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0033\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0033\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0032\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0031\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0031\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0030\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0029\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0029\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0028\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0028\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0024\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0023\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0023\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0023\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0022\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0022\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0021\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0021\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0020\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0020\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0019\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0019\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0019\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0018\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0018\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0018\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0017\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0016\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0014\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0014\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0012\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0012\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0010\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0010\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0010\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.8147e-04\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.6131e-04\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.4156e-04\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.2222e-04\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.0328e-04\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.8472e-04\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.6655e-04\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.4875e-04\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.3132e-04\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.1425e-04\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.9752e-04\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.8114e-04\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.6510e-04\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.4938e-04\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.3399e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1cb0043eb0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(xs, ys, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "[[18.920956]]\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "print(model.predict([10.0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
